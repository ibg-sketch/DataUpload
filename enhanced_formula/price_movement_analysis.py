#!/usr/bin/env python3
"""
Deep Price Movement Analysis
Analyzes correlation between signal parameters and actual price movements
"""

import pandas as pd
import numpy as np
from datetime import datetime
from scipy import stats

TRAINING_CUTOFF = "2025-11-04 12:21:00"

def load_and_merge_data():
    """Load and merge all data sources"""
    df_eff = pd.read_csv('effectiveness_log.csv')
    df_sig = pd.read_csv('signals_log.csv')
    
    # Filter to new data
    df_eff = df_eff[df_eff['timestamp_sent'] >= TRAINING_CUTOFF].copy()
    
    # Prepare for merge
    df_eff['ts_key'] = pd.to_datetime(df_eff['timestamp_sent']).dt.strftime('%Y-%m-%d %H:%M')
    df_sig['ts_key'] = pd.to_datetime(df_sig['timestamp']).dt.strftime('%Y-%m-%d %H:%M')
    
    # Merge datasets
    df = pd.merge(df_eff, df_sig, on=['ts_key', 'symbol'], how='left', suffixes=('', '_sig'))
    
    return df

def calculate_price_metrics(df):
    """Calculate additional price movement metrics"""
    df_completed = df[df['result'].isin(['WIN', 'LOSS'])].copy()
    
    # Max favorable movement (how far price went in our direction)
    df_completed['max_favorable_pct'] = np.where(
        df_completed['verdict'] == 'BUY',
        (df_completed['highest_reached'] - df_completed['entry_price']) / df_completed['entry_price'] * 100,
        (df_completed['entry_price'] - df_completed['lowest_reached']) / df_completed['entry_price'] * 100
    )
    
    # Max adverse movement (how far price went against us)
    df_completed['max_adverse_pct'] = np.where(
        df_completed['verdict'] == 'BUY',
        (df_completed['entry_price'] - df_completed['lowest_reached']) / df_completed['entry_price'] * 100,
        (df_completed['highest_reached'] - df_completed['entry_price']) / df_completed['entry_price'] * 100
    )
    
    # Price volatility during signal
    df_completed['price_volatility'] = df_completed['max_favorable_pct'] + df_completed['max_adverse_pct']
    
    # Target achievement rate
    df_completed['target_min_achieved'] = np.where(
        df_completed['target_min'] > 0,
        df_completed['max_favorable_pct'] >= (df_completed['target_min'] - df_completed['entry_price']).abs() / df_completed['entry_price'] * 100,
        np.nan
    )
    
    return df_completed

def analyze_profit_correlations(df):
    """Analyze correlation between parameters and profit size"""
    print("="*80)
    print("–ö–û–†–†–ï–õ–Ø–¶–ò–Ø –ü–ê–†–ê–ú–ï–¢–†–û–í –° –†–ê–ó–ú–ï–†–û–ú –ü–†–û–§–ò–¢–ê (profit_pct)")
    print("="*80)
    
    # Parameters to analyze
    params = {
        'score': '–û–±—â–∏–π Score',
        'confidence': 'Confidence',
        'oi_change': 'OI Change',
        'rsi': 'RSI',
        'cvd_strength': 'CVD Strength',
        'volume_ratio': 'Volume Ratio',
        'ttl_minutes': 'TTL Duration',
        'volume_spike': 'Volume Spike',
        'liq_long': 'Long Liquidations',
        'liq_short': 'Short Liquidations'
    }
    
    correlations = []
    
    print("\n–ü–∞—Ä–∞–º–µ—Ç—Ä              | –ö–æ—Ä—Ä. | P-value | –ó–Ω–∞—á–∏–º–æ—Å—Ç—å | –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ")
    print("-"*80)
    
    for param, label in params.items():
        if param in df.columns:
            # Filter out NaN values and convert to numeric
            valid_data = df[[param, 'profit_pct']].copy()
            valid_data[param] = pd.to_numeric(valid_data[param], errors='coerce')
            valid_data['profit_pct'] = pd.to_numeric(valid_data['profit_pct'], errors='coerce')
            valid_data = valid_data.dropna()
            
            if len(valid_data) > 5:
                corr, p_value = stats.pearsonr(valid_data[param].astype(float), valid_data['profit_pct'].astype(float))
                
                # Significance
                if p_value < 0.01:
                    significance = "***"
                elif p_value < 0.05:
                    significance = "**"
                elif p_value < 0.10:
                    significance = "*"
                else:
                    significance = "n.s."
                
                # Strength
                if abs(corr) > 0.3:
                    strength = "–°–ò–õ–¨–ù–ê–Ø"
                elif abs(corr) > 0.15:
                    strength = "–°—Ä–µ–¥–Ω—è—è"
                else:
                    strength = "–°–ª–∞–±–∞—è"
                
                # Direction
                direction = "‚Üë –ë–æ–ª—å—à–µ=–í—ã—à–µ –ø—Ä–∏–±—ã–ª—å" if corr > 0 else "‚Üì –ë–æ–ª—å—à–µ=–ù–∏–∂–µ –ø—Ä–∏–±—ã–ª—å"
                
                correlations.append((param, label, corr, p_value))
                print(f"{label:20s} | {corr:+.3f} | {p_value:.4f} | {significance:10s} | {direction}")
    
    print("\n–õ–µ–≥–µ–Ω–¥–∞ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏: *** p<0.01 (–≤—ã—Å–æ–∫–∞—è), ** p<0.05 (—Å—Ä–µ–¥–Ω—è—è), * p<0.10 (–Ω–∏–∑–∫–∞—è), n.s. (–Ω–µ –∑–Ω–∞—á–∏–º–∞)")
    
    return correlations

def analyze_movement_strength(df):
    """Analyze correlation with maximum favorable movement"""
    print("\n" + "="*80)
    print("–ö–û–†–†–ï–õ–Ø–¶–ò–Ø –° –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–´–ú –î–í–ò–ñ–ï–ù–ò–ï–ú –í –ù–ê–®–£ –°–¢–û–†–û–ù–£")
    print("="*80)
    
    params = ['score', 'confidence', 'oi_change', 'rsi', 'cvd_strength', 'volume_ratio', 'ttl_minutes']
    
    print("\n–ü–∞—Ä–∞–º–µ—Ç—Ä              | –ö–æ—Ä—Ä. | P-value | –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è")
    print("-"*80)
    
    for param in params:
        if param in df.columns:
            valid_data = df[[param, 'max_favorable_pct']].copy()
            valid_data[param] = pd.to_numeric(valid_data[param], errors='coerce')
            valid_data['max_favorable_pct'] = pd.to_numeric(valid_data['max_favorable_pct'], errors='coerce')
            valid_data = valid_data.dropna()
            
            if len(valid_data) > 5:
                corr, p_value = stats.pearsonr(valid_data[param].astype(float), valid_data['max_favorable_pct'].astype(float))
                
                if abs(corr) > 0.2 and p_value < 0.1:
                    interpretation = "‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–∏–ª—É –¥–≤–∏–∂–µ–Ω–∏—è"
                elif abs(corr) < 0.1:
                    interpretation = "‚ûñ –ù–µ –≤–ª–∏—è–µ—Ç –Ω–∞ –¥–≤–∏–∂–µ–Ω–∏–µ"
                else:
                    interpretation = "‚ö†Ô∏è –°–ª–∞–±–æ–µ –≤–ª–∏—è–Ω–∏–µ"
                
                print(f"{param:20s} | {corr:+.3f} | {p_value:.4f} | {interpretation}")

def analyze_volatility_patterns(df):
    """Analyze which parameters predict high volatility"""
    print("\n" + "="*80)
    print("–ü–†–ï–î–ò–ö–¢–û–†–´ –í–û–õ–ê–¢–ò–õ–¨–ù–û–°–¢–ò")
    print("="*80)
    
    params = ['score', 'confidence', 'oi_change', 'cvd_strength', 'volume_ratio']
    
    print("\n–ü–∞—Ä–∞–º–µ—Ç—Ä              | –ö–æ—Ä—Ä. | –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è")
    print("-"*80)
    
    for param in params:
        if param in df.columns:
            valid_data = df[[param, 'price_volatility']].copy()
            valid_data[param] = pd.to_numeric(valid_data[param], errors='coerce')
            valid_data['price_volatility'] = pd.to_numeric(valid_data['price_volatility'], errors='coerce')
            valid_data = valid_data.dropna()
            
            if len(valid_data) > 5:
                corr, p_value = stats.pearsonr(valid_data[param].astype(float), valid_data['price_volatility'].astype(float))
                
                if corr > 0.2 and p_value < 0.1:
                    interpretation = "üìä –í—ã—Å–æ–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ ‚Üí –í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å"
                elif corr < -0.2 and p_value < 0.1:
                    interpretation = "üìâ –í—ã—Å–æ–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ ‚Üí –ù–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å"
                else:
                    interpretation = "‚ûñ –ù–µ –≤–ª–∏—è–µ—Ç –Ω–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å"
                
                print(f"{param:20s} | {corr:+.3f} | {interpretation}")

def analyze_by_profit_quartiles(df):
    """Analyze parameter distributions across profit quartiles"""
    print("\n" + "="*80)
    print("–ê–ù–ê–õ–ò–ó –ü–û –ö–í–ê–†–¢–ò–õ–Ø–ú –ü–†–ò–ë–´–õ–ò")
    print("="*80)
    
    # Create profit quartiles
    df['profit_quartile'] = pd.qcut(df['profit_pct'], q=4, labels=['Q1_Worst', 'Q2_Below_Avg', 'Q3_Above_Avg', 'Q4_Best'])
    
    params = ['score', 'confidence', 'oi_change', 'rsi']
    
    print("\n–°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ –∫–≤–∞—Ä—Ç–∏–ª—è–º –ø—Ä–∏–±—ã–ª–∏:")
    print("-"*80)
    
    for param in params:
        if param in df.columns:
            print(f"\n{param}:")
            quartile_means = df.groupby('profit_quartile')[param].agg(['mean', 'median', 'count'])
            
            for quartile in ['Q1_Worst', 'Q2_Below_Avg', 'Q3_Above_Avg', 'Q4_Best']:
                if quartile in quartile_means.index:
                    mean = quartile_means.loc[quartile, 'mean']
                    median = quartile_means.loc[quartile, 'median']
                    count = quartile_means.loc[quartile, 'count']
                    print(f"  {quartile:15s}: mean={mean:7.2f}, median={median:7.2f}, n={count}")

def analyze_target_achievement(df):
    """Analyze what predicts target achievement"""
    print("\n" + "="*80)
    print("–î–û–°–¢–ò–ñ–ï–ù–ò–ï –¶–ï–õ–ï–í–´–• –£–†–û–í–ù–ï–ô")
    print("="*80)
    
    # Filter signals with valid targets
    df_with_targets = df[df['target_min_achieved'].notna()].copy()
    
    if len(df_with_targets) > 0:
        achieved = df_with_targets['target_min_achieved'].sum()
        total = len(df_with_targets)
        
        print(f"\n–¶–µ–ª—å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞: {achieved}/{total} ({achieved/total*100:.1f}%)")
        
        # Compare parameters between achieved and not achieved
        params = ['score', 'confidence', 'oi_change', 'cvd_strength']
        
        print("\n–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–î–æ—Å—Ç–∏–≥–ª–∏ vs –ù–µ –¥–æ—Å—Ç–∏–≥–ª–∏):")
        print("-"*80)
        
        for param in params:
            if param in df_with_targets.columns:
                achieved_mean = df_with_targets[df_with_targets['target_min_achieved'] == True][param].mean()
                not_achieved_mean = df_with_targets[df_with_targets['target_min_achieved'] == False][param].mean()
                diff_pct = (achieved_mean - not_achieved_mean) / not_achieved_mean * 100 if not_achieved_mean != 0 else 0
                
                print(f"{param:20s}: –î–æ—Å—Ç–∏–≥–ª–∏={achieved_mean:7.2f} | –ù–µ –¥–æ—Å—Ç–∏–≥–ª–∏={not_achieved_mean:7.2f} | –†–∞–∑–Ω–∏—Ü–∞={diff_pct:+6.1f}%")

def analyze_direction_specific_correlations(df):
    """Analyze correlations separately for BUY and SELL"""
    print("\n" + "="*80)
    print("–ö–û–†–†–ï–õ–Ø–¶–ò–ò –û–¢–î–ï–õ–¨–ù–û –î–õ–Ø BUY –ò SELL")
    print("="*80)
    
    params = ['score', 'confidence', 'oi_change', 'rsi']
    
    for direction in ['BUY', 'SELL']:
        df_dir = df[df['verdict'] == direction]
        
        if len(df_dir) > 5:
            print(f"\n{direction} —Å–∏–≥–Ω–∞–ª—ã (n={len(df_dir)}):")
            print("-"*80)
            
            for param in params:
                if param in df_dir.columns:
                    valid_data = df_dir[[param, 'profit_pct']].copy()
                    valid_data[param] = pd.to_numeric(valid_data[param], errors='coerce')
                    valid_data['profit_pct'] = pd.to_numeric(valid_data['profit_pct'], errors='coerce')
                    valid_data = valid_data.dropna()
                    
                    if len(valid_data) > 3:
                        corr, p_value = stats.pearsonr(valid_data[param].astype(float), valid_data['profit_pct'].astype(float))
                        sig = "‚úÖ" if p_value < 0.1 else "‚ûñ"
                        print(f"  {param:20s}: {corr:+.3f} (p={p_value:.3f}) {sig}")

def find_best_combinations(df):
    """Find parameter combinations that predict highest profits"""
    print("\n" + "="*80)
    print("–û–ü–¢–ò–ú–ê–õ–¨–ù–´–ï –ö–û–ú–ë–ò–ù–ê–¶–ò–ò –ü–ê–†–ê–ú–ï–¢–†–û–í")
    print("="*80)
    
    # High OI change combinations
    print("\n–í—ã—Å–æ–∫–∏–π OI Change (>0) –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏:")
    print("-"*80)
    
    high_oi = df[df['oi_change'] > 0]
    
    conditions = [
        ('RSI < 40 (Oversold)', high_oi[high_oi['rsi'] < 40]),
        ('RSI > 60 (Overbought)', high_oi[high_oi['rsi'] > 60]),
        ('Confidence < 70%', high_oi[high_oi['confidence'] < 0.70]),
        ('Confidence > 70%', high_oi[high_oi['confidence'] >= 0.70]),
    ]
    
    for label, subset in conditions:
        if len(subset) > 2:
            avg_profit = subset['profit_pct'].mean()
            win_rate = (subset['result'] == 'WIN').sum() / len(subset) * 100
            print(f"{label:25s}: n={len(subset):2d}, WR={win_rate:5.1f}%, Avg Profit={avg_profit:+6.2f}%")
    
    # Low confidence but high OI
    print("\n–ù–∏–∑–∫–∞—è Confidence (<70%) + –í—ã—Å–æ–∫–∏–π OI:")
    low_conf_high_oi = df[(df['confidence'] < 0.70) & (df['oi_change'] > 0)]
    if len(low_conf_high_oi) > 0:
        avg_profit = low_conf_high_oi['profit_pct'].mean()
        win_rate = (low_conf_high_oi['result'] == 'WIN').sum() / len(low_conf_high_oi) * 100
        print(f"  –°–∏–≥–Ω–∞–ª–æ–≤: {len(low_conf_high_oi)}")
        print(f"  Win Rate: {win_rate:.1f}%")
        print(f"  Avg Profit: {avg_profit:+.2f}%")

def generate_actionable_insights(correlations, df):
    """Generate specific actionable recommendations"""
    print("\n" + "="*80)
    print("–ö–û–ù–ö–†–ï–¢–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ù–ê –û–°–ù–û–í–ï –î–ê–ù–ù–´–•")
    print("="*80)
    
    # Sort correlations by absolute value
    sorted_corr = sorted(correlations, key=lambda x: abs(x[2]), reverse=True)
    
    print("\n1. –ü–†–ò–û–†–ò–¢–ï–¢–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´ –î–õ–Ø –ú–û–î–ï–õ–ò:")
    print("-"*80)
    for param, label, corr, p_value in sorted_corr[:5]:
        if p_value < 0.1:
            if corr > 0:
                action = f"–£–≤–µ–ª–∏—á–∏—Ç—å –≤–µ—Å - –∫–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Å –ø—Ä–∏–±—ã–ª—å—é ({corr:+.3f})"
            else:
                action = f"–ü–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ - –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è ({corr:+.3f})"
            print(f"  ‚Ä¢ {label:20s}: {action}")
    
    # Confidence paradox analysis
    print("\n2. –ü–†–û–ë–õ–ï–ú–ê CONFIDENCE:")
    print("-"*80)
    high_conf = df[df['confidence'] >= 0.80]
    low_conf = df[(df['confidence'] >= 0.50) & (df['confidence'] < 0.70)]
    
    if len(high_conf) > 0 and len(low_conf) > 0:
        high_conf_profit = high_conf['profit_pct'].mean()
        low_conf_profit = low_conf['profit_pct'].mean()
        
        print(f"  –í—ã—Å–æ–∫–∞—è confidence (80-100%): {high_conf_profit:+.2f}% —Å—Ä–µ–¥–Ω–∏–π –ø—Ä–æ—Ñ–∏—Ç")
        print(f"  –ù–∏–∑–∫–∞—è confidence (50-70%):   {low_conf_profit:+.2f}% —Å—Ä–µ–¥–Ω–∏–π –ø—Ä–æ—Ñ–∏—Ç")
        
        if low_conf_profit > high_conf_profit:
            print("  ‚ö†Ô∏è  –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–ë–õ–ï–ú–ê: –ù–∏–∑–∫–∞—è confidence –¥–∞–µ—Ç –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã!")
            print("  ‚Üí –§–æ—Ä–º—É–ª–∞ confidence —Ä–∞–±–æ—Ç–∞–µ—Ç –ù–ê–û–ë–û–†–û–¢")
            print("  ‚Üí –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –ò–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–ª–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å")
    
    # Best parameter ranges
    print("\n3. –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ï –î–ò–ê–ü–ê–ó–û–ù–´ –ü–ê–†–ê–ú–ï–¢–†–û–í:")
    print("-"*80)
    
    # OI Change optimal range
    if 'oi_change' in df.columns:
        oi_positive = df[df['oi_change'] > 0]
        oi_negative = df[df['oi_change'] <= 0]
        
        if len(oi_positive) > 0 and len(oi_negative) > 0:
            pos_profit = oi_positive['profit_pct'].mean()
            neg_profit = oi_negative['profit_pct'].mean()
            
            print(f"  OI Change > 0: {pos_profit:+.2f}% (n={len(oi_positive)})")
            print(f"  OI Change ‚â§ 0: {neg_profit:+.2f}% (n={len(oi_negative)})")
            
            if pos_profit > neg_profit:
                print("  ‚Üí –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –¢—Ä–µ–±–æ–≤–∞—Ç—å OI Change > 0 –¥–ª—è –≤—Å–µ—Ö —Å–∏–≥–Ω–∞–ª–æ–≤")
    
    # RSI optimal ranges
    if 'rsi' in df.columns:
        rsi_oversold = df[df['rsi'] < 40]
        rsi_neutral = df[(df['rsi'] >= 40) & (df['rsi'] <= 60)]
        rsi_overbought = df[df['rsi'] > 60]
        
        print(f"\n  RSI < 40 (Oversold):   {rsi_oversold['profit_pct'].mean():+.2f}% (n={len(rsi_oversold)})")
        print(f"  RSI 40-60 (Neutral):   {rsi_neutral['profit_pct'].mean():+.2f}% (n={len(rsi_neutral)})")
        print(f"  RSI > 60 (Overbought): {rsi_overbought['profit_pct'].mean():+.2f}% (n={len(rsi_overbought)})")

def main():
    print("="*80)
    print("–ì–õ–£–ë–û–ö–ò–ô –ê–ù–ê–õ–ò–ó –î–í–ò–ñ–ï–ù–ò–Ø –¶–ï–ù –ò –ö–û–†–†–ï–õ–Ø–¶–ò–ô")
    print("="*80)
    print(f"–î–∞—Ç–∞ —Å—Ä–µ–∑–∞: {TRAINING_CUTOFF}")
    print(f"–í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # Load data
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    df = load_and_merge_data()
    df_completed = calculate_price_metrics(df)
    
    print(f"–ó–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(df_completed)}")
    print(f"  WIN: {(df_completed['result'] == 'WIN').sum()}")
    print(f"  LOSS: {(df_completed['result'] == 'LOSS').sum()}")
    print()
    
    # Run analyses
    correlations = analyze_profit_correlations(df_completed)
    analyze_movement_strength(df_completed)
    analyze_volatility_patterns(df_completed)
    analyze_by_profit_quartiles(df_completed)
    analyze_target_achievement(df_completed)
    analyze_direction_specific_correlations(df_completed)
    find_best_combinations(df_completed)
    generate_actionable_insights(correlations, df_completed)
    
    print("\n" + "="*80)
    print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù")
    print("="*80)
    print("\n–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
    print("  1. –ü—Ä–∏–º–µ–Ω–∏—Ç—å –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
    print("  2. –ü–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å —Ñ–æ—Ä–º—É–ª—É confidence –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π")
    print("  3. –£–≤–µ–ª–∏—á–∏—Ç—å –≤–µ—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π")
    print("  4. –°–æ–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (—Ü–µ–ª—å: 100+ —Å–∏–≥–Ω–∞–ª–æ–≤)")

if __name__ == '__main__':
    main()
